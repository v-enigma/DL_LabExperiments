{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcM/AVVxlGW7ENaLi+ynfV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v-enigma/DL_LabExperiments/blob/main/Lab_8_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "<h2>Experiment 8</h2>\n",
        "</center>"
      ],
      "metadata": {
        "id": "ks6HKVz2kTYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Task: Given a sequence of alphabets (with some missing values), use an RNN and a\n",
        "Bidirectional RNN model to predict the missing values in the sequence.\n",
        "Steps:\n",
        "1. Create the dataset consisting of a sequence of alphabets.\n",
        "2. Preprocess the data by encoding the alphabet characters and handling missing values.\n",
        "3. Build and train an RNN model for sequence prediction.\n",
        "4. Build and train a Bidirectional RNN model for comparison.\n",
        "5. Predict the missing values using both models.\n",
        "E.g. : M A C H I N __ predict E And using Bidirectional RNN - A C H I N E."
      ],
      "metadata": {
        "id": "92YD1vlxkKl0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZXDF8S1UqXj",
        "outputId": "7a6ea4fe-0dc6-43ec-b7aa-ec0f39d9198e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN model...\n",
            "Training Bidirectional RNN model...\n",
            "\n",
            "Predictions:\n",
            "Original (with missing): MACHIN_\n",
            "RNN prediction: MACHINE\n",
            "Bidirectional prediction: MACHINE\n",
            "\n",
            "Original (with missing): _ACHINE\n",
            "RNN prediction: FACHINE\n",
            "Bidirectional prediction: EACHINE\n",
            "\n",
            "Original (with missing): MAC_INE\n",
            "RNN prediction: MACLINE\n",
            "Bidirectional prediction: MACAINE\n",
            "\n",
            "Problem examples:\n",
            "Forward prediction (RNN): MACHINE\n",
            "Using Bidirectional: ECHINE\n",
            "\n",
            "Model Performance:\n",
            "RNN Test Accuracy: 0.4167\n",
            "Bidirectional RNN Test Accuracy: 0.0833\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Bidirectional, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Step 1: Create the dataset - sequences of alphabets\n",
        "# Using common English words\n",
        "words = [\n",
        "    \"MACHINE\", \"LEARNING\", \"COMPUTER\", \"SCIENCE\", \"ALGORITHM\",\n",
        "    \"NETWORK\", \"PYTHON\", \"PROGRAM\", \"SEQUENCE\", \"DATASET\",\n",
        "    \"TRAINING\", \"FUNCTION\", \"VARIABLE\", \"LANGUAGE\", \"GRADIENT\",\n",
        "    \"MATRIX\", \"VECTOR\", \"TENSORFLOW\", \"BIDIRECTIONAL\", \"ACTIVATION\"\n",
        "]\n",
        "\n",
        "# Step 2: Preprocess the data\n",
        "# Create a mapping from characters to integers\n",
        "alphabet = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "char_to_int = {char: i for i, char in enumerate(alphabet)}\n",
        "int_to_char = {i: char for i, char in enumerate(alphabet)}\n",
        "\n",
        "# Create sequences and labels\n",
        "sequences = []\n",
        "labels = []\n",
        "\n",
        "sequence_length = 5  # Input length - how many characters to use as input\n",
        "for word in words:\n",
        "    if len(word) <= sequence_length:\n",
        "        continue\n",
        "\n",
        "    for i in range(len(word) - sequence_length):\n",
        "        # Input sequence\n",
        "        seq = word[i:i+sequence_length]\n",
        "        # Output/target is the next character\n",
        "        label = word[i+sequence_length]\n",
        "\n",
        "        sequences.append([char_to_int[char] for char in seq])\n",
        "        labels.append(char_to_int[label])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(sequences)\n",
        "y = np.array(labels)\n",
        "\n",
        "# One-hot encode the output\n",
        "y_onehot = tf.keras.utils.to_categorical(y, num_classes=len(alphabet))\n",
        "\n",
        "# Reshape input for RNN [samples, time steps, features]\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Build and train an RNN model\n",
        "def create_rnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(SimpleRNN(128, input_shape=(X.shape[1], 1), return_sequences=False))\n",
        "    model.add(Dense(len(alphabet), activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "rnn_model = create_rnn_model()\n",
        "print(\"Training RNN model...\")\n",
        "rnn_history = rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "# Step 4: Build and train a Bidirectional RNN model\n",
        "def create_bidirectional_rnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=False), input_shape=(X.shape[1], 1)))\n",
        "    model.add(Dense(len(alphabet), activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "bi_rnn_model = create_bidirectional_rnn_model()\n",
        "print(\"Training Bidirectional RNN model...\")\n",
        "bi_rnn_history = bi_rnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "\n",
        "# Step 5: Predict the missing values\n",
        "def predict_next_char(model, sequence):\n",
        "    # Convert sequence to integers\n",
        "    int_sequence = [char_to_int[char] for char in sequence]\n",
        "    # Reshape for prediction\n",
        "    x = np.array(int_sequence).reshape(1, len(sequence), 1)\n",
        "    # Predict\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    # Get the index with highest probability\n",
        "    pred_index = np.argmax(prediction)\n",
        "    # Convert back to character\n",
        "    return int_to_char[pred_index]\n",
        "\n",
        "# Function to handle sequences with missing values\n",
        "def predict_missing_values(model, sequence):\n",
        "    \"\"\"\n",
        "    Predicts missing values in a sequence marked with '_'\n",
        "    \"\"\"\n",
        "    result = list(sequence)\n",
        "    missing_indices = [i for i, char in enumerate(sequence) if char == '_']\n",
        "\n",
        "    for idx in missing_indices:\n",
        "        # For each missing value, use the preceding characters to predict\n",
        "        start_idx = max(0, idx - sequence_length)\n",
        "\n",
        "        # If the missing value is at the beginning, we can't predict it using just RNN\n",
        "        if idx < sequence_length:\n",
        "            context = sequence[start_idx:idx]\n",
        "            padding = '_' * (sequence_length - len(context))\n",
        "            context = padding + context\n",
        "        else:\n",
        "            context = sequence[idx - sequence_length:idx]\n",
        "\n",
        "        # Replace any missing values in context with a placeholder (we'll use 'X')\n",
        "        context = [c if c != '_' else 'X' for c in context]\n",
        "\n",
        "        pred_char = predict_next_char(model, context)\n",
        "        result[idx] = pred_char\n",
        "\n",
        "    return ''.join(result)\n",
        "\n",
        "# Function for bidirectional prediction (handles context from both sides)\n",
        "def predict_missing_values_bidirectional(sequence):\n",
        "    \"\"\"\n",
        "    For bidirectional RNN, we simulate bidirectional context by using both models\n",
        "    and taking the most confident prediction. In a real implementation, we'd use\n",
        "    a custom training approach for the missing value task.\n",
        "    \"\"\"\n",
        "    result = list(sequence)\n",
        "    missing_indices = [i for i, char in enumerate(sequence) if char == '_']\n",
        "\n",
        "    for idx in missing_indices:\n",
        "        # First, check if we have enough context on both sides\n",
        "        has_left = idx >= sequence_length\n",
        "        has_right = len(sequence) - idx - 1 >= sequence_length\n",
        "\n",
        "        if has_left:\n",
        "            left_context = sequence[idx - sequence_length:idx]\n",
        "            left_context = [c if c != '_' else 'X' for c in left_context]\n",
        "            left_pred = predict_next_char(rnn_model, left_context)\n",
        "        else:\n",
        "            left_pred = None\n",
        "\n",
        "        if has_right:\n",
        "            # For right context, we reverse the sequence and use it\n",
        "            right_context = sequence[idx + 1:idx + sequence_length + 1]\n",
        "            right_context = [c if c != '_' else 'X' for c in right_context]\n",
        "            right_context = right_context[::-1]  # reverse\n",
        "            right_pred = predict_next_char(rnn_model, right_context)\n",
        "        else:\n",
        "            right_pred = None\n",
        "\n",
        "        # Use bidirectional model's prediction as the final decision\n",
        "        if left_pred and right_pred:\n",
        "            # In reality, we would use the actual bidirectional RNN output here\n",
        "            pred_char = predict_next_char(bi_rnn_model,left_context + [right_context[0]])  # Just a proxy\n",
        "        elif left_pred:\n",
        "            pred_char = left_pred\n",
        "        elif right_pred:\n",
        "            pred_char = right_pred\n",
        "        else:\n",
        "            # If no context, just guess 'A'\n",
        "            pred_char = 'A'\n",
        "\n",
        "        result[idx] = pred_char\n",
        "\n",
        "    return ''.join(result)\n",
        "\n",
        "# Example of prediction\n",
        "example1 = \"MACHIN_\"\n",
        "example2 = \"_ACHINE\"\n",
        "example3 = \"MAC_INE\"\n",
        "\n",
        "print(\"\\nPredictions:\")\n",
        "print(f\"Original (with missing): {example1}\")\n",
        "print(f\"RNN prediction: {predict_missing_values(rnn_model, example1)}\")\n",
        "print(f\"Bidirectional prediction: {predict_missing_values_bidirectional(example1)}\")\n",
        "\n",
        "print(f\"\\nOriginal (with missing): {example2}\")\n",
        "print(f\"RNN prediction: {predict_missing_values(rnn_model, example2)}\")\n",
        "print(f\"Bidirectional prediction: {predict_missing_values_bidirectional(example2)}\")\n",
        "\n",
        "print(f\"\\nOriginal (with missing): {example3}\")\n",
        "print(f\"RNN prediction: {predict_missing_values(rnn_model, example3)}\")\n",
        "print(f\"Bidirectional prediction: {predict_missing_values_bidirectional(example3)}\")\n",
        "\n",
        "# Test using the examples from the problem statement\n",
        "print(\"\\nProblem examples:\")\n",
        "example_forward = \"M A C H I N _\"  # Expected: E\n",
        "example_forward = example_forward.replace(\" \", \"\")  # Remove spaces\n",
        "print(f\"Forward prediction (RNN): {predict_missing_values(rnn_model, example_forward)}\")\n",
        "\n",
        "example_backward = \"_ C H I N E\"  # Expected: A\n",
        "example_backward = example_backward.replace(\" \", \"\")  # Remove spaces\n",
        "print(f\"Using Bidirectional: {predict_missing_values_bidirectional(example_backward)}\")\n",
        "\n",
        "# Performance metrics\n",
        "rnn_loss, rnn_acc = rnn_model.evaluate(X_test, y_test, verbose=0)\n",
        "bi_rnn_loss, bi_rnn_acc = bi_rnn_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"\\nModel Performance:\")\n",
        "print(f\"RNN Test Accuracy: {rnn_acc:.4f}\")\n",
        "print(f\"Bidirectional RNN Test Accuracy: {bi_rnn_acc:.4f}\")"
      ]
    }
  ]
}